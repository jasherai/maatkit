#!/usr/bin/perl

# This program efficiently checksums MySQL tables on one or more servers.
#
# This program is copyright (c) 2007 Baron Schwartz, baron at xaprb dot com.
# Feedback and improvements are welcome.
#
# THIS PROGRAM IS PROVIDED "AS IS" AND WITHOUT ANY EXPRESS OR IMPLIED
# WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
# MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE.
#
# This program is free software; you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, version 2; OR the Perl Artistic License.  On UNIX and similar
# systems, you can issue `man perlgpl' or `man perlartistic' to read these
# licenses.
#
# You should have received a copy of the GNU General Public License along with
# this program; if not, write to the Free Software Foundation, Inc., 59 Temple
# Place, Suite 330, Boston, MA  02111-1307  USA.

# TODO: account for difference in timestamp format between servers (can
# SELECT CURRENT_TIMESTAMP to detect)

use strict;
use warnings FATAL => 'all';

use DBI;
use English qw(-no_match_vars);
use Getopt::Long;
use List::Util qw(min max);
use POSIX qw(ceil);
use Term::ReadKey;

our $VERSION = '@VERSION@';

$OUTPUT_AUTOFLUSH = 1;

# ############################################################################
# Get configuration information.
# ############################################################################

# Define cmdline args; each is GetOpt::Long spec, whether required,
# human-readable description.  Add more hash entries as needed.
my @opt_spec = (
   { s => 'algorithm|a=s',     d => 'Checksum algorithm (ACCUM|CHECKSUM|BIT_XOR)' },
   { s => 'askpass',           d => 'Prompt for username and password for connections' },
   { s => 'chunkcol=s',        d => 'Explicitly specifies a column to use for chunking' },
   { s => 'chunksize-approx',  d => 'Allow approximate chunk sizes' },
   { s => 'chunksize|C=i',     d => 'Number of rows to checksum at a time (disallows -a CHECKSUM)' },
   { s => 'databases|d=s',     d => 'Only do this comma-separated list of databases' },
   { s => 'defaults-file|F=s', d => 'Only read default options from the given file' },
   { s => 'emptyrepltbl',      d => 'Empty table given by --replicate before starting' },
   { s => 'engine|e=s',        d => 'Only do this comma-separated list of storage engines' },
   { s => 'float-precision=i', d => 'Precision for FLOAT and DOUBLE column comparisons' },
   { s => 'function|f=s',      d => 'Cryptographic hash function (SHA1, MD5...)' },
   { s => 'help',              d => 'Show this help message' },
   { s => 'ignoredb|g=s',      d => 'Ignore this comma-separated list of databases' },
   { s => 'ignoretbl|n=s',     d => 'Ignore this comma-separated list of tables' },
   { s => 'index|i=s',         d => 'Index to use for ACCUM checksum algorithm' },
   { s => 'lock|k',            d => 'Lock table on master until done on slaves (implies -l)' },
   { s => 'count|r!',          d => 'Do the count (default)' },
   { s => 'crc|c!',            d => 'Do the CRC (default)' },
   { s => 'optxor|o!',         d => 'Optimize BIT_XOR with user variables (default)'},
   { s => 'password|p=s',      d => 'Password to use when connecting' },
   { s => 'port|P=i',          d => 'Port number to use for connection' },
   { s => 'quiet|q',           d => 'Do not print checksum results' },
   { s => 'replicate|R=s',     d => 'Replicate checksums in a table (disallows -a CHECKSUM)' },
   { s => 'slavelag|l',        d => 'Report how far slaves lag master' },
   { s => 'separator|s=s',     d => 'Separator for CONCAT_WS()' },
   { s => 'sleep=i',           d => 'Sleep time between checksums' },
   { s => 'sleep-coef=f',      d => 'Sleep time as a multiple of last checksum time' },
   { s => 'socket|S=s',        d => 'Socket file to use for connection' },
   { s => 'tab|b',             d => 'Output separated with tabs' },
   { s => 'tables|t=s',        d => 'Only do this comma-separated list of tables' },
   { s => 'user|u=s',          d => 'User for login if not current user' },
   { s => 'verify|v!',         d => 'Verify checksum compatibility across servers (default)' },
   { s => 'wait|w=i',          d => 'How long to do MASTER_POS_WAIT() on slaves (implies -kl)' },
   { s => 'where|W=s',         d => 'Only do rows matching this WHERE clause (disallows -a CHECKSUM)' },
);

# This is the container for the command-line options' values to be stored in
# after processing.  Initial values are defaults.
my %opts = (
   W => '',
   o => 1,
   r => 0,
   c => 1,
   s => '#',
   v => 1,
);

# Post-process...
my %opt_seen;
foreach my $spec ( @opt_spec ) {
   my ( $long, $short ) = $spec->{s} =~ m/^([\w-]+)(?:\|([^!+=]*))?/;
   $spec->{k} = $short || $long;
   $spec->{l} = $long;
   $spec->{t} = $short;
   $spec->{n} = $spec->{s} =~ m/!/;
   $opts{$spec->{k}} = undef unless defined $opts{$spec->{k}};
   die "Duplicate option $spec->{k}" if $opt_seen{$spec->{k}}++;
}

Getopt::Long::Configure('no_ignore_case', 'bundling');
GetOptions( map { $_->{s} => \$opts{$_->{k}} } @opt_spec) or $opts{help} = 1;

# Post-process command-line options and arguments.
$opts{k} ||= defined $opts{w};
$opts{l} ||= $opts{k};

# Make comma-separated lists into hashes.
if ( $opts{d} ) {
   $opts{d} = { map { $_ => 1 } split(/,\s*/, $opts{d}) };
}
$opts{g} = { map { $_ => 1 } split(/,\s*/, $opts{g} || '') };
if ( $opts{t} ) {
   $opts{t} = { map { $_ => 1 } split(/,\s*/, $opts{t}) };
}
$opts{n} = { map { $_ => 1 } split(/,\s*/, $opts{n} || '') };
if ( $opts{e} ) {
   $opts{e} = { map { lc($_) => 1 } split(/,\s*/, $opts{e}) };
}

# Don't let someone put a ' in the separator
$opts{s} =~ s/'//g;

# Create a WHERE clause
$opts{W} = $opts{W} ? " WHERE $opts{W}" : '';

if ( $opts{a} && $opts{a} !~ m/^(?:ACCUM|CHECKSUM|BIT_XOR)$/ ) {
   warn "--algorithm=$opts{a}: unknown algorithm.\n";
   $opts{help} = 1;
}

if ( !@ARGV ) {
   warn "No hosts specified.\n";
   $opts{help} = 1;
}

my @hosts = unique(@ARGV);
if ( $opts{R} && @hosts > 1 ) {
   die "You can only specify one host with --replicate\n";
}

if ( $opts{help} ) {
   print "Usage: mysql-table-checksum [OPTION]... HOST [HOST...]\n\n";
   my $maxw = max(map { length($_->{l}) + ($_->{n} ? 4 : 0)} @opt_spec);
   foreach my $spec ( sort { $a->{l} cmp $b->{l} } @opt_spec ) {
      my $long  = $spec->{n} ? "[no]$spec->{l}" : $spec->{l};
      my $short = $spec->{t} ? "-$spec->{t}" : '';
      printf("  --%-${maxw}s %-4s %s\n", $long, $short, $spec->{d});
   }
   print <<USAGE;

mysql-table-checksum efficiently checksums MySQL tables on one or more hosts.
If you specify multiple hosts, the first is assumed to be the master.
Connection options are read from MySQL option files.  For more details, please
read the documentation:

   perldoc mysql-table-checksum

USAGE
   exit(1);
}

# ############################################################################
# Ready to work now.
# ############################################################################

my $exit_status = 0;

my $db_options = {
   RaiseError => 1,
   PrintError => 0,
   AutoCommit => $opts{k} ? 0 : 1,
};

my %db_info; # holds user/pass etc for each host

my $main_dbh  = get_dbh($hosts[0], ($opts{d} ? keys %{$opts{d}} : '' ));
$main_dbh->{InactiveDestroy} = 1; # Can't be set in $db_options
my @databases = @{$main_dbh->selectcol_arrayref('SHOW DATABASES')};

# Figure out what strategy to use
my $strat;
if ( (!$opts{a} || $opts{a} eq 'CHECKSUM')   # By default, use CHECKSUM TABLE
   && !$opts{W} && !$opts{C}                 # CHECKSUM does whole table
   && !$opts{R}                              # CHECKSUM can't be INSERT.. SELECTed
   && version_ge($main_dbh, '4.1.1') )       # CHECKSUM doesn't exist before this
{
   if ( !$opts{a} && $opts{r} ) {
      # The user didn't specify an algorithm, but wants a count, which is
      # inefficient with CHECKSUM TABLE.  Since the user didn't explicitly
      # demand this poor strategy, we fall back to another.
      $strat = 'ACCUM';
   }
   else {
      # Alas, the user wants me to be stupid and run two queries where one would
      # suffice.  (This can actually be a good strategy on MyISAM, and is even
      # better when MyISAM's live checksums are enabled).
      $strat = 'CHECKSUM';
   }
}
elsif (!$opts{a} || $opts{a} eq 'ACCUM') {   # Fall back to ACCUM
   $strat = 'ACCUM';
}
elsif ( $opts{a} eq 'BIT_XOR'
   && version_ge($main_dbh, '4.1.1') )       # BIT_XOR() doesn't exist before this
{
   $strat = 'BIT_XOR';
}
else {
   $strat = 'ACCUM';                         # Fallback if all else fails
}
if ( $opts{a} && $opts{a} ne $strat ) {
   warn "--algorithm=$opts{a} can't be used; falling back to $strat\n";
}

# If using a cryptographic hash strategy, decide what hash function to use.
my $func = $opts{f} || 'SHA1';
if ( $strat =~ m/ACCUM|BIT_XOR/ ) {
   my $res = eval { $main_dbh->do("SELECT $func('test-string')") };
   if ( !$res ) {
      my $err = '';
      if ( $EVAL_ERROR && $EVAL_ERROR =~ m/failed: (.*?) at \S+ line/ ) {
         $err = qq{ because "$1"};
      }
      if ( lc $func eq 'md5' ) {  # There's nothing to fall back to
         die "Cryptographic function $func cannot be used$err\n";
      }
      warn "Cryptographic function $func cannot be used$err; falling back to MD5()\n";
      $func = 'MD5';
   }
}

my $crc_wid   = max(16, length(($main_dbh->selectrow_array("SELECT $func('a')"))[0]));
my $crc_slice = 0;
my $sanity    = '';

# Figure out which slice in a sliced BIT_XOR checksum should have the actual
# concat-columns-and-checksum, and which should just get variable references.
if ( $opts{o} && $strat eq 'BIT_XOR' ) {
   my $desired = uc $main_dbh->selectall_arrayref("SELECT $func('a')")->[0]->[0];
   my $result  = '';
   my $start   = 1;

   do { # Try different positions till sliced result equals non-sliced.
      $main_dbh->do('SET @crc := NULL, @cnt := 0');
      my $slices = make_slices("\@crc := $func('a')");
      my $sanity = "SELECT CONCAT($slices) as test from (select null) as t";
      $result    = $main_dbh->selectall_arrayref($sanity)->[0]->[0];
      if ( $result ne $desired ) {
         $start += 16;
         ++$crc_slice;
      }
   } while ( $start < $crc_wid && $result ne $desired );

   if ( $result ne $desired ) {
      # Disable the user-variable optimization.
      warn "Cannot get good checksums with --optxor, disabling.\n";
      $opts{o} = 0;
   }
}

if ( $opts{v} && @hosts > 1 ) {
   # Verify that CONCAT_WS is compatible across all servers.  On older versions
   # of MySQL it skips both empty strings and NULL; on newer just NULL.
   my @verify_sums;
   my @verify_vars;
   foreach my $host ( @hosts ) {
      my $dbh = get_dbh($host, ($opts{d} ? keys %{$opts{d}} : '' ));
      my $cks = $dbh->selectall_arrayref("SELECT MD5(CONCAT_WS(',', '1', ''))")->[0]->[0];
      push @verify_sums, { host => $host, ver => $dbh->{mysql_serverinfo}, sum => $cks };
      if ( $sanity ) {
         # Also verify all servers treat user-variables the same way.
         $dbh->do('SET @crc := NULL, @cnt := 0');
         $cks = $dbh->selectall_arrayref($sanity)->[0]->[0];
         push @verify_vars, { host => $host, ver => $dbh->{mysql_serverinfo}, sum => $cks };
      }
   }
   if ( unique(map { $_->{sum} } @verify_sums ) > 1 ) {
      my $max = max(map { length($_) } @hosts);
      die "Not all servers have compatible versions.  Some return different\n"
         . "checksum values for the same query, and cannot be compared.  This\n"
         . "behavior changed in MySQL 4.0.14.  Here is info on each host:\n\n"
         . join("\n",
            map { sprintf("%-${max}s %-32s %s", @{$_}{qw(host sum ver)}) }
            { host => 'HOST', sum => 'CHECKSUM', ver => 'VERSION'}, @verify_sums)
         . "\n\nYou can disable this check with --noverify.\n";
   }

   # Also check @verify_vars (not @verify_sums... I almost deleted this as
   # crap code till I noticed that it's not the same variable name).
   if ( unique(map { $_->{sum} } @verify_vars ) > 1 ) {
      # No need to die, just disable the variable optimization.
      $opts{o} = 0;
   }
}

my ($fetch_sth, $update_sth);
if ( $opts{R} ) {
   # Check for the existence of, and optionally clean out, the replication table before starting.
   $main_dbh->do("DESCRIBE $opts{R}"); # Ignore the result; this is a no-op
   if ( $opts{emptyrepltbl} ) {
      $main_dbh->do("DELETE FROM $opts{R}");
   }
   $fetch_sth = $main_dbh->prepare(
      "SELECT this_crc, this_cnt FROM $opts{R} WHERE db = ? AND tbl = ? AND chunk = ?");
   $update_sth = $main_dbh->prepare(
      "UPDATE $opts{R} SET master_crc = ?, master_cnt = ? WHERE db = ? AND tbl = ? AND chunk = ?");
}

DATABASE:
foreach my $database ( @databases ) {
   next DATABASE if
      ( $opts{d} && !exists($opts{d}->{$database}) )
      || $database =~ m/^(information_schema|lost\+found)$/mi
      || exists $opts{g}->{$database};

   my @tables = @{$main_dbh->selectcol_arrayref("SHOW TABLES FROM `$database`")};
   next DATABASE unless @tables;

   my %info_for;
   TABLE:
   foreach my $table ( @tables ) {
      next TABLE if
         ( $opts{t} && !exists($opts{t}->{$table}) )
         || ( $opts{R} && $opts{R} eq "$database.$table" )
         || exists $opts{n}->{$table};

      # Get the table type, and a query to generate a checksum for it.
      eval {
         my ( $engine, $query, $chunk_col ) = checksum_query( $main_dbh, $database, $table );

         # Skip views, and tables of the wrong engine.
         if ( $engine ne 'VIEW' && (!$opts{e} || $opts{e}->{lc($engine)}) ) {
            $info_for{$table} = {
               database  => $database,
               table     => $table,
               engine    => $engine,
               query     => $query,
               chunk_col => $chunk_col,
            };
         }

      };
      if ( $EVAL_ERROR ) {
         print_err($EVAL_ERROR);
      }

   }

   next DATABASE unless %info_for;

   # Design and print header
   my $hdr;
   if ( $opts{b} ) {
      $hdr = "%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n";
   }
   else {
      my $max_tbl  = max(5, map { length($_) } keys %info_for);
      my $max_db   = max(8, length($database));
      my $max_host = max(4, map { length($_) } @hosts);
      $hdr         = "%-${max_db}s %-${max_tbl}s %5s %-${max_host}s %-6s %10s %${crc_wid}s %4s %4s %4s %4s\n";
   }
   my @hdr_args = qw(DATABASE TABLE CHUNK HOST ENGINE COUNT CHECKSUM TIME WAIT STAT LAG);
   printf($hdr, @hdr_args) unless $opts{q};

   TABLE:
   foreach my $table ( sort keys %info_for ) {

      my $info      = $info_for{$table};
      my $table_min = 0;
      my $table_max = undef;
      my $chunk_size = $opts{C};
      if ( $info->{chunk_col} && $opts{C} ) {
         # Determine the range of values for the chunk_col column on this table.
         my $chunk_sql = "SELECT COALESCE(MIN($info->{chunk_col}), 0), COALESCE(MAX($info->{chunk_col}), 0) "
            . "FROM `$info->{database}`.`$info->{table}`$opts{W}";
         eval {
            ( $table_min, $table_max ) = $main_dbh->selectrow_array($chunk_sql);
         };
         if ( $EVAL_ERROR ) {
            print_err($EVAL_ERROR);
            next TABLE;
         }
         if ( $opts{'chunksize-approx'} ) {
            my $expl = $main_dbh->selectrow_hashref(
               "EXPLAIN SELECT * FROM `$info->{database}`.`$info->{table}`$opts{W}");
            if ( $expl && $expl->{rows} ) {
               $chunk_size = ceil( $opts{C} * ( $table_max - $table_min ) / $expl->{rows} ) || $opts{C};
            }
         }
      }

      $info->{chunk_cur} = 1;
      $info->{chunk_min} = $table_min;
      if ( $info->{chunk_col} && $opts{C} ) {
         $info->{chunk_max} = $info->{chunk_min} + $chunk_size - 1;
         $info->{chunk_tot} = ceil(($table_max - $table_min)/$chunk_size);
      }
      else {
         $info->{chunk_max} = $table_max;
         $info->{chunk_tot} = 0;
      }

      # Do a chunk at a time.
      do {
         my $chunk_start_time = time;
         if ( $opts{R} ) { # We're in --replicate mode.
            eval {
               do_tbl_replicate($hosts[0], $info_for{$table}, $hdr);
            };
            if ( $EVAL_ERROR ) {
               print_err($EVAL_ERROR);
            }
         }

         else {

            # Lock table and get master position on the master, if applicable.
            $main_dbh->do("LOCK TABLES `$database`.`$table` READ") if $opts{k};
            if ( defined $opts{w} ) {
               my $master_status = $main_dbh->selectrow_hashref('SHOW MASTER STATUS');
               @{$info_for{$table}}{keys %$master_status} = values %$master_status;
            }

            my %children;
            foreach my $host ( @hosts ) {
               my $pid = @hosts > 1 ? fork() : undef;
               if ( @hosts == 1 || (defined($pid) && $pid == 0) ) { # I am a child
                  eval {
                     do_tbl($host, $info_for{$table}, $host eq $hosts[0], $hdr);
                  };
                  if ( $EVAL_ERROR ) {
                     print_err($EVAL_ERROR);
                     exit(1); # die, even if only a single host
                  }
                  exit(0) if @hosts > 1; # exit only if I'm a child
               }
               elsif ( @hosts > 1 && !defined($pid) ) {
                  die("Unable to fork!");
               }
               # I already exited if I'm a child, so I'm the parent.
               $children{$host} = $pid if @hosts > 1;
            }

            # Wait for the children to exit.
            foreach my $host ( keys %children ) {
               my $pid = waitpid($children{$host}, 0);
               $exit_status = $CHILD_ERROR;
            }
            $main_dbh->do("UNLOCK TABLES") if $opts{k};

         }

         if ( $info->{chunk_col} && $opts{C} ) {
            $info->{chunk_min} = $info->{chunk_max} + 1;
            $info->{chunk_max} = $info->{chunk_max} + $chunk_size;
            $info->{chunk_cur}++;
         }

         if ( $opts{sleep} ) {
            sleep($opts{sleep});
         }
         elsif ( $opts{'sleep-coef'} ) {
            my $sleep_time = ceil( (time - $chunk_start_time) * $opts{'sleep-coef'} );
            sleep($sleep_time);
         }

      } while ( defined $table_max && $info->{chunk_min} <= $table_max );
   }
}

sub add_progress_comment {
   my ( $query, $info ) = @_;
   $query =~ s/progress_comment/$info->{database}.$info->{table}:$info->{chunk_cur}\/$info->{chunk_tot}/;
   return $query;
}

sub do_tbl_replicate {
   my ( $host, $info, $hdr ) = @_;
   my $dbh = $main_dbh;
   my $cnt = 'NULL';
   my $crc = 'NULL';
   my $beg = time();
   $dbh->do('SET @crc := NULL, @cnt := 0 /*!50108 , @@binlog_format := "STATEMENT"*/');
   $dbh->do(
      add_progress_comment($info->{query}, $info), {},
      ( $info->{chunk_cur} ),
      $info->{chunk_col} && $opts{C} ? @{$info}{qw(chunk_min chunk_max)} : ()
   );
   $fetch_sth->execute(@{$info}{qw(database table chunk_cur)});
   ( $crc, $cnt ) = $fetch_sth->fetchrow_array();
   $update_sth->execute($crc, $cnt, @{$info}{qw(database table chunk_cur)});
   my $end = time();
   $crc  ||= 'NULL';
   printf($hdr, @{$info}{qw(database table chunk_cur)}, $host, $info->{engine}, $cnt, $crc,
      $end - $beg, 'NULL', 'NULL', 'NULL') unless $opts{q};
}

sub do_tbl {
   my ( $host, $info, $is_master, $hdr ) = @_;
   my $dbh = get_dbh($host, $info->{database});
   my $cnt = 'NULL';
   my $crc = 'NULL';
   my $sta = 'NULL';
   my $lag = 'NULL';
   my $beg = time();
   if ( !$is_master && defined $opts{w} ) {
      $sta = $dbh->selectall_arrayref(
         add_progress_comment(
            "SELECT /*progress_comment*/ MASTER_POS_WAIT('$info->{File}', $info->{Position}, $opts{w})",
            $info
         ))->[0]->[0];
      $sta = 'NULL' unless defined $sta;
   }
   if ( !$is_master && $opts{l} ) {
      my $res = $dbh->selectrow_hashref("SHOW SLAVE STATUS");
      $lag = $res && defined $res->{Seconds_Behind_Master}
           ? $res->{Seconds_Behind_Master}
           : 'NULL';
   }
   my $mid = time();
   if ( $strat eq 'CHECKSUM' ) {
      if ( $opts{c} ) {
         $crc = $dbh->selectall_arrayref("CHECKSUM TABLE `$info->{database}`.`$info->{table}`",
            { Slice => {} })->[0]->{Checksum};
      }
      if ( $opts{r} ) {
         $cnt = do_count($dbh, $info);
      }
   }
   elsif ( $opts{c} ) {
      ( $cnt, $crc ) = do_var_crc($dbh, $info);
      $crc ||= 'NULL';
   }
   else {
      $cnt = do_count($dbh, $info);
   }
   my $end = time();
   $dbh->disconnect();
   printf($hdr, @{$info}{qw(database table chunk_cur)}, $host, $info->{engine}, $cnt, $crc,
      $end - $mid, $mid - $beg, $sta, $lag) unless $opts{q};
}

sub checksum_query {
   my ( $dbh, $db, $tbl ) = @_;
   my $ddl = ($dbh->selectrow_array("SHOW CREATE TABLE `$db`.`$tbl`"))[1];
   return ( 'VIEW', '', '' ) if $ddl =~ m/^CREATE ALGORITHM/;

   my ( $type ) = $ddl =~ m/^\) (?:ENGINE|TYPE)=(\S+)/m;

   # Make a list of all columns.
   my @defs = $ddl =~ m/^(\s+`.*)$/gm;
   my @tocrc;
   foreach my $def ( @defs ) {
      my ($name, $type) = $def =~ m/(`[^`]+`)\s([a-z]+)/;
      die "Can't parse column definition $def" unless $name;
      push @tocrc,
           $type =~ m/float|double/ && $opts{'float-precision'} ? "ROUND($name, $opts{'float-precision'})"
         :                                                        $name;
   }

   # See if there's a column that will support chunking.  Single col only.
   my $chunk_col = $opts{chunkcol} || '';
   if ( $opts{C} && !$chunk_col ) {
      if ( grep { $_ =~ m/AUTO_INCREMENT/ } @defs ) {
         ($chunk_col) = map { $_ =~ m/(`[^`]+`)/g } grep { $_ =~ m/AUTO_INCREMENT/ } @defs;
      }
      else {
         my @candidates;
         if (!$opts{'chunksize-approx'}) {
            @candidates = $ddl =~ m/(?:PRIMARY|UNIQUE) KEY .*?\((`[^`]+`)\)/g;
         } else {
            @candidates = $ddl =~ m/(?:PRIMARY |UNIQUE )?KEY .*?\((`[^`]+`)[^\)]*\)/g;
         }
         @candidates = grep {
            my $idx = $_;
            grep { m/^  $idx (?:tiny|big|small|medium)?int/m } @defs;
         } @candidates;
         if ( @candidates ) {
            $chunk_col = $candidates[0];
         }
      }
   }

   # To detect when columns are NULL, make a bitmap of nullable columns.
   my @nulls = map { $_ =~ m/(`[^`]+`)/g } grep { $_ !~ m/NOT NULL/ } @defs;
   if ( @nulls ) {
      push @tocrc, "CONCAT(" . join(', ', map { "ISNULL($_)" } @nulls) . ")";
   }

   # Design the column checksum expression.
   my $chks = @tocrc > 1
            ? "$func(CONCAT_WS('$opts{s}', " . join(',', @tocrc) . '))'
            : "$func($tocrc[0])";

   # Make the query.
   my $query = '';
   if ( $strat eq 'BIT_XOR' ) {

      # This checksum algorithm concatenates the columns in each row and
      # checksums them, then slices this checksum up into 16-character chunks.
      # It then converts them BIGINTs with the CONV() function, and then
      # groupwise XORs them to produce an order-independent checksum of the
      # slice over all the rows.  It then converts these back to base 16 and
      # puts them back together.  The effect is the same as XORing a very wide
      # (32 characters = 128 bits for MD5, and SHA1 is even larger) unsigned
      # integer over all the rows.

      my $slices = make_slices($chks);

      if ( $opts{R} ) {
         $query = "REPLACE /*progress_comment*/ INTO $opts{R}(db, tbl, chunk, this_cnt, this_crc) "
            . "SELECT '$db', '$tbl', ?, COUNT(*), CONCAT($slices) AS crc FROM `$db`.`$tbl`$opts{W}";
      }
      else {
         $query = "SELECT /*progress_comment*/ COUNT(*) as cnt, CONCAT($slices) AS crc FROM `$db`.`$tbl`$opts{W}";
      }

   }
   else { # Use an accumulator variable.
      # Find whether there's a PK (for order-by).  Since the accumulator
      # variable re-checksums every row combined with the previous row's
      # checksum, row order matters.
      my $index = $opts{i}                           ? " USE INDEX(`$opts{i}`)"
                : $ddl =~ m/PRIMARY KEY\s*\((.*?)\)/ ? ' USE INDEX(PRIMARY)'
                : '';

      # Generate the query.  This query relies on @crc being NULL, and @cnt
      # being 0 when it begins.  It checksums each row, appends it to the
      # running checksum, and checksums the two together.  In this way it acts
      # as an accumulator for all the rows.  It then prepends a steadily
      # increasing number to the left, left-padded with zeroes, so each
      # checksum taken is stringwise greater than the last.  In this way the
      # MAX() function can be used to return the last checksum calculated.
      # @cnt is not used for a row count, it is only used to make MAX() work
      # correctly.
      if ( $opts{R} ) {
         $query = "REPLACE /*progress_comment*/ INTO $opts{R}(db, tbl, chunk, this_cnt, this_crc) "
            . "SELECT '$db', '$tbl', ?, COUNT(*) AS cnt, RIGHT(MAX("
            . "\@crc := CONCAT(LPAD(\@cnt := \@cnt + 1, 16, '0'), $func(CONCAT_WS('$opts{s}', \@crc, $chks)))"
            . "), $crc_wid) AS crc FROM `$db`.`$tbl`$index$opts{W}";
      }
      else {
         $query = "SELECT /*progress_comment*/ COUNT(*) AS cnt, RIGHT(MAX("
            . "\@crc := CONCAT(LPAD(\@cnt := \@cnt + 1, 16, '0'), $func(CONCAT_WS('$opts{s}', \@crc, $chks)))"
            . "), $crc_wid) AS crc FROM `$db`.`$tbl`$index$opts{W}";
      }
   }

   if ( $chunk_col && $opts{C} ) {
      $query .= ($opts{W} ? ' AND ' : ' WHERE ')
             .  "$chunk_col BETWEEN ? AND ?";
   }

   return ( $type, $query, $chunk_col );
}

sub make_slices {
   my ( $chks ) = @_;

   # Split the CRC result up into slices and glue them together.
   my @slices;
   for ( my $start = 1; $start < $crc_wid; $start += 16 ) {
      my $len = min(16, $crc_wid - $start + 1);
      push @slices,
         "LPAD(CONV(BIT_XOR("
         . "CAST(CONV(SUBSTRING(\@crc, $start, $len), 16, 10) AS UNSIGNED))"
         . ", 10, 16), $len, '0')";
   }

   if ( $crc_slice < @slices && $opts{o} ) {
      $slices[$crc_slice] =~ s/\@crc/\@crc := $chks/;
   }
   else {
      map { s/\@crc/$chks/ } @slices;
   }

   return join(', ', @slices);
}

exit $exit_status;

# ############################################################################
# Subroutines
# ############################################################################

sub get_dbh {
   my ( $host, $db ) = @_;
   my %conn = ( F => 'mysql_read_default_file', h => 'host', P => 'port', S => 'socket');

   if ( $opts{askpass} ) {
      if ( !$db_info{$host} ) {
         print "Username for $host: ";
         my $user = <STDIN>;
         chomp $user;
         print "Password for $user on $host: ";
         ReadMode('noecho');
         my $pass = <STDIN>;
         chomp $pass;
         ReadMode('normal');
         print "\n";
         $db_info{$host} = { u => $user, p => $pass };
      }
      $opts{u} = $db_info{$host}->{u};
      $opts{p} = $db_info{$host}->{p};
   }

   $db ||= '';
   my $dsn = "DBI:mysql:$db;host=$host;"
      . join(';', map  { "$conn{$_}=$opts{$_}" } grep { defined $opts{$_} } qw(F h P S))
      . ';mysql_read_default_group=mysql';
   return DBI->connect($dsn, @opts{qw(u p)}, $db_options )
      or die("Can't connect to DB: $OS_ERROR");
}

sub do_var_crc {
   my ( $dbh, $info ) = @_;
   $dbh->do('set @crc := NULL, @cnt := 0');
   my $res = $dbh->selectall_arrayref(
      add_progress_comment($info->{query}, $info),
      { Slice => {} },
      $info->{chunk_col} && $opts{C} ? ( @{$info}{qw(chunk_min chunk_max)}) : ()
   )->[0];
   return ($res->{cnt}, $res->{crc});
}

sub do_count {
   my ( $dbh, $info ) = @_;
   return $dbh->selectall_arrayref(
      "SELECT COUNT(*) FROM `$info->{database}`.`$info->{table}`$opts{W}"
   )->[0]->[0];
}

sub unique {
   my %seen;
   grep { !$seen{$_}++ } @_;
}

# Compares versions like 5.0.27 and 4.1.15-standard-log
sub version_ge {
   my ( $dbh, $target ) = @_;
   my $version = sprintf('%03d%03d%03d', $dbh->{mysql_serverinfo} =~ m/(\d+)/g);
   return $version ge sprintf('%03d%03d%03d', $target =~ m/(\d+)/g);
}

# Tries to extract the MySQL error message and print it
sub print_err {
   my ( $msg ) = @_;
   return if !defined $msg
      # Honor --quiet in the (common?) event that a table went away
      or ($opts{q} && $EVAL_ERROR =~ m/doesn't exist/);
   $msg =~ s/^.*?failed: (.*?) at \S+ line (\d+).*$/$1 at line $2/s;
   print STDERR $msg, "\n";
}

# ############################################################################
# Documentation
# ############################################################################
=pod

=head1 NAME

mysql-table-checksum - Efficiently checksum MySQL tables on one or many servers.

=head1 SYNOPSIS

  mysql-table-checksum --replicate=mydb.checksum master-host

Or,

  mysql-table-checksum host host1 host2 ... hostN | mysql-checksum-filter

=head1 OVERVIEW

This program generates table checksums for MySQL tables, typically useful for
verifying your slaves are in sync with the master.  The checksums are
generated by a query on the server, and there is virtually no network traffic
as a result.

Checksums typically take about twice as long as COUNT(*) on very large InnoDB
tables in my tests.  For smaller tables, COUNT(*) is a good bit faster than
the checksums.  See --algorithm for more details on performance.

If you specify more than one server, mysql-table-checksum assumes the first
server is the master and others are slaves.  Checksums are parallelized for
speed, forking off a child process for each table.  Duplicate server names are
ignored, but if you want to checksum a server against itself you can use two
different forms of the hostname (for example, localhost and 127.0.0.1).

mysql-table-checksum only examines table structure on the first host specified,
so if anything differs on the others, it won't notice.  It ignores views.

The checksums are tested on MySQL version 3.23.58 through 6.0-alpha.

=head1 OPTIONS

Many options are enabled by default and can be disabled by prefixing with --no.

=over

=item --algorithm

Specifies which checksum algorithm to use.  Valid arguments are CHECKSUM,
BIT_XOR and ACCUM.  The latter two do cryptographic hash checksums.

CHECKSUM is built into MySQL, but has some disadvantages.  BIT_XOR and ACCUM are
implemented by the SQL queries mysql-table-checksum generates.  They use a
cryptographic hash of all columns concatenated together with a separator,
followed by a bitmap of each nullable column that is NULL (necessary because
CONCAT_WS() skips NULL columns).

CHECKSUM is the default.  This method uses MySQL's built-in CHECKSUM TABLE
command.  It cannot be used before MySQL 4.1.1, and various options disable it
as well.  It does not simultaneously count rows; that requires an extra COUNT(*)
query.  This is a good option when you are using MyISAM tables with live
checksums enabled; in this case both the COUNT(*) and CHECKSUM queries will run
very quickly.  CHECKSUM TABLE is a little faster than the other two
algorithms, but not very much.

The BIT_XOR algorithm is available for MySQL 4.1.1 and newer.  It uses
BIT_XOR(), which is order-independent, to reduce all the rows to a single
checksum.  It runs within an order of magnitude of COUNT(*) on InnoDB tables;
on large tables it's typically about half as fast as COUNT(*).

ACCUM uses a user variable as an accumulator.  It reduces each row to a single
checksum, which is concatenated with the accumulator and re-checksummed.  This
technique is order-dependent.  If the table has a primary key, it will be used
to order the results for consistency; otherwise it's up to chance.  It tends to
use a little less CPU and run a little faster than the BIT_XOR algorithm.

The ACCUM algorithm has two possible advantages over BIT_XOR: speed (there may
be fewer cryptographic hash operations and it may read less data) and possibly
fewer collisions.  The pathological worst case is where identical rows will
cancel each other out in the BIT_XOR.  In this case you will not be able to
distinguish a table full of one value from a table full of another value.  The
ACCUM algorithm will distinguish them.

However, the ACCUM algorithm is order-dependent, so if you have two tables
with identical data but the rows are out of order, you'll get different
checksums with ACCUM.

Choose your (mild) poison.  Each algorithm is very good in reality.  If a given
algorithm won't work for some reason, mysql-table-checksum falls back to
another.  The least common denominator is ACCUM, which works on MySQL 3.23.2 and
newer.

One reason to specify a cryptographic hash algorithm instead of CHECKSUM is to
checksum tables that have the same data but different row formats (possibly
because of different storage engines), and thus will return different values for
CHECKSUM TABLE.

=item --askpass

Prompt for a username and password for each host.

=item --chunkcol

Specifies a column for chunking (see --chunksize).  You should not need to do
this normally, because mysql-table-checksum can find a suitable column if one
exists.  Be careful of using character columns, because mysql-table-checksum's
chunking algorithm works only on numbers.  For instance, if you have a character
column containing values 1 through 90 and you specify a chunksize of 50,
mysql-table-checksum will checksum BETWEEN 1 AND 50, then BETWEEN 51 and 100.
The second query will not match any rows because of character collations.

=item --chunksize

If you specify a chunk size, mysql-table-checksum will look for an integer
column that is a PRIMARY or UNIQUE key on each table, preferring AUTO_INCREMENT.
The column must be the only column in the key.  If there is such a key,
mysql-table-checksum will checksum the table in parts with a BETWEEN in the
WHERE clause, and will do no more than the number of rows you specify in a
single chunk.

If it cannot find a suitable column, it will do the entire table in one
checksum just as though you had not specified --chunksize at all.  Each table is
handled individually, so some tables may be chunked and others not, if it can't
find a good column.

You can override the checks for uniqueness and integer data type by specifying
a column explicitly, but this may not do what you want.  See --chunkcol for more
information.

=item --chunksize-approx

If this option is enabled, mysql-table-checksum will checksum the table in
chunks similar to --chunksize, but the chunk sizes will be approximate, and
may exceed the value you specify.  The chunk sizes are determined by
estimating the number of rows and the density of the key values.  This also
enables mysql-table-checksum to use the chunking algorithm with multi-column
indexes, provided the first column is an integer type.

=item --count

Count the rows as well as taking their checksum. This is disabled by default to
avoid an extra COUNT(*) query when --algorithm is CHECKSUM.  For other
algorithms, you get a count for free.  If you have only MyISAM tables and live
checksums are enabled, both CHECKSUM and COUNT will be very fast, but otherwise
you may want to use one of the other algorithms.

=item --crc

Take the checksum of the rows as well as their count.  This is enabled by
default.  If you disable it, you'll just get COUNT(*) queries.

=item --databases

Only checksum this comma-separated list of databases.

=item --defaults-file

If you specify this option, only this file is read for MySQL default options;
otherwise all the default files will be read.

=item --emptyrepltbl

Issues a DELETE against the table given by --replicate before beginning work.
Ignored if --replicate is not specified.  This can be useful to remove entries
related to tables that no longer exist.

=item --engine

Only checksum tables whose storage engine is in this comma-separated list.
You can use this to restrict the checksum to InnoDB, for example.

=item --float-precision

If you specify this option, FLOAT and DOUBLE columns will be rounded to the
specified number of digits after the decimal point for the checksum.  This can
avoid checksum mismatches due to different floating-point representations of
the same values on different MySQL versions and hardware.

=item --function

You can use this option to choose the cryptographic hash function used for
--algorithm=ACCUM or --algorithm=BIT_XOR.  The default is to use SHA1, but MD5
is also a good choice.  Whatever function you specify is run in SQL, not in
Perl, so it must be available to MySQL.

=item --ignoredb

Use this option to skip a comma-separated list of databases.

=item --ignoretbl

Use this option to skip a comma-separated list of tables.

=item --index

If you specify --algorithm=ACCUM and the table has no PRIMARY KEY, row ordering
will be non-deterministic, and you may get unpredictable results.  If there is
another index that will give predictable results, this option can be used to
specify it.

=item --lock

This option can help you to get a consistent read on a master and many slaves.
If you specify this option, mysql-table-checksum will lock the table on the
first server on the command line, which it assumes to be the master.  It will
keep this lock until the checksums complete on the other servers.

This option isn't very useful by itself, so you probably want to use --wait
instead.

=item --optxor

This option, which is enabled by default, specifies to use user variables to
reduce the number of times each row must be passed through the cryptographic
hash function when you are using the BIT_XOR algorithm.

With the optimization, the queries look like this in pseudo-code:

  SELECT CONCAT(
     BIT_XOR(SLICE_OF(@user_variable)),
     BIT_XOR(SLICE_OF(@user_variable)),
     ...
     BIT_XOR(SLICE_OF(@user_variable := HASH(col1, col2... colN))));

The exact positioning of user variables and calls to the hash function is
determined dynamically, and will vary between MySQL versions.  Without the
optimization, it looks like this:

  SELECT CONCAT(
     BIT_XOR(SLICE_OF(MD5(col1, col2... colN))),
     BIT_XOR(SLICE_OF(MD5(col1, col2... colN))),
     ...
     BIT_XOR(SLICE_OF(MD5(col1, col2... colN))));

The difference is the number of times all the columns must be mashed together
and fed through the hash function.  If you are checksumming really large
columns, such as BLOB or TEXT columns, this might make a big difference.

=item --password

The password to use when connecting.

=item --port

The port number to use for the connection.

=item --replicate

This option enables a completely different checksum strategy for a consistent,
lock-free checksum across a master and its slaves.  This only works with
statement-based replication (mysql-table-checksum will switch the binlog format
to STATEMENT for the duration of the session if your server uses row-based
replication).  Instead of running the checksum queries on each server, you only
run it on the master.  You specify a table to insert the results into.  The
query will insert directly into the table, so it will be replicated through the
binlog to the slaves.

The argument to the option is the table in which the checksums should be
stored.  The table must have at least these columns: db, tbl, chunk, this_crc,
master_crc, this_cnt, master_cnt.  Here is a suggested table structure:

  CREATE TABLE checksum (
     db         char(64)     NOT NULL,
     tbl        char(64)     NOT NULL,
     chunk      int          NOT NULL,
     this_crc   char(40)     NOT NULL,
     this_cnt   int          NOT NULL,
     master_crc char(40)         NULL,
     master_cnt int              NULL,
     ts         timestamp    NOT NULL,
     PRIMARY KEY (db, tbl, chunk)
  );

When the queries are finished replicating, you can run a simple query on each
slave to see which tables have differences from the master.  See L<"CONSISTENT
CHECKSUMS"> for details.

This option eliminates the need to do complicated locking and unlocking,
waiting for master binlog positions, and so on.  It disables --lock, --wait,
and --slavelag.

The checksum queries actually do a REPLACE into this table, so existing rows
need not be removed before running.  However, you may wish to do this anyway
to remove rows related to tables that don't exist anymore.  The --emptyrepltbl
option does this for you.

=item --separator

This option controls the separator character used for CONCAT_WS() when taking
row checksums with user-variables.

=item --slavelag

If this option is enabled, the output will show how many seconds behind the
master each slave is.  This can be useful when you want a fast, parallel,
non-blocking checksum, and you know your slaves might lag the master.  You can
inspect the results and make an educated guess whether any discrepancies on the
slave are due to slave lag instead of corrupt data.

=item --sleep

If this option is specified, mysql-table-checksum will sleep the specified
number of seconds between checksums.  That is, it will sleep between every
table, and if you specify --chunksize, it will also sleep between chunks.

=item --sleep-coef

If this option is specified, mysql-table-checksum will sleep the amount of
time elapsed during the previous checksum, multiplied by the specified
coefficient.  This option is ignored if --sleep is specified.

=item --socket

The socket file to use for the connection.

=item --tab

Instead of column-aligned output, print tab-separated output.

=item --tables

Restrict checksums to this comma-separated list of tables.

=item --user

MySQL user account to use for the connection.

=item --verify

This option is enabled by default.  It runs a trivial checksum on all servers to
ensure they have compatible CONCAT_WS() and cryptographic hash functions.

Versions of MySQL before 4.0.14 will skip empty strings and NULLs in
CONCAT_WS, and others will only skip NULLs.  The two kinds of behavior will
produce different results if you have any columns containing the empty string
in your table.  If you know you don't (for instance, all columns are
integers), you can safely disable this check and you will get a reliable
checksum even on servers with different behavior.

This option also checks all servers to be sure the --optxor optimization will
work correctly.  If not, it simply disables the optimization, rather than
stopping with an error.

=item --wait

This option helps you get a consistent checksum across a master server and its
slaves.  It combines locking and waiting to accomplish this.  First it locks the
table on the master (the first server on the command line).  Then it finds the
master's binlog position and checksums.

The argument to the option is the number of seconds to wait for the slaves to
catch up to the master.  It is actually the argument to MASTER_POS_WAIT().  If
the slaves don't catch up to the master within this time, they will unblock
and go ahead with the checksum.  You can tell whether this happened by
examining the STAT column in the output.

=item --where

You can use this option to limit the checksum to only part of the table.  This
is particularly useful if you have append-only tables and don't want to
constantly re-check all rows; you could run a daily job to just check
yesterday's rows, for instance.

This option is much like the -w option to mysqldump.  Do not specify the WHERE
keyword.  You may need to quote the value.  Here is an example:

  mysql-table-checksum --where "foo=bar"

=back

=head1 CONSISTENT CHECKSUMS

If you are using this tool to verify your slaves still have the same data as the
master, which is why I wrote it, you should read this section.

The best way to do this with replication is to use the --replicate option.  When
the queries are finished running on the master and its slaves, you can go to the
slaves and issue SQL queries to see if any tables are different from the master.
Try the following:

  SELECT db, tbl, chunk, this_cnt-master_cnt AS cnt_diff,
     this_crc<>master_crc AS crc_diff
  FROM checksum
  WHERE master_cnt <> this_cnt OR master_crc <> this_crc;

If you can't use this method, try the following:

=over

=item *

If your servers are not being written to, you can just run the tool with no
further ado:

  mysql-table-checksum server1 server2 ... serverN

=item *

If the servers are being written to, you need some way to make sure they are
consistent at the moment you run the checksums.  For situations other than
master-slave replication, you will have to figure this out yourself.  You may
be able to use the --where option with a date or time column to only checksum
data that's not recent.

=item *

If you are checksumming a master and slaves, you can do a fast parallel
checksum and assume the slaves are caught up to the master.  In practice, this
tends to work well except for tables which are constantly updated.  You can
use the --slavelag option to see how far behind each slave was when it
checksummed a given table.  This can help you decide whether to investigate
further.

=item *

The next most disruptive technique is to lock the table on the master, then take
checksums.  This should prevent changes from propagating to the slaves.  You can
just lock on the master (with --lock), or you can both lock on the master and wait
on the slaves till they reach that point in the master's binlog (--wait).  Which is
better depends on your workload; only you know that.

=item *

If you decide to make the checksums on the slaves wait until they're guaranteed
to be caught up to the master, the algorithm looks like this:

 For each table,
   Master: lock table
   Master: get pos
   In parallel,
     Master: checksum
     Slave(s): wait for pos, then checksum
   End
   Master: unlock table
 End

=back

What I typically do when I'm not using the --replicate option is simply run the
tool on all servers with no further options.  This runs fast, parallel,
non-blocking checksums simultaneously.  If there are tables that look different,
I re-run with --wait=600 on the tables in question.  This makes the tool lock on
the master as explained above.

=head1 OUTPUT

Output is to STDOUT, one line per server and table, with header lines for each
database.  I tried to make the output easy to process with awk.  For this reason
columns are always present.  If there's no value, mysql-table-checksum prints 'NULL'.

The default is column-aligned output for human readability, but you can change
it to tab-separated if you want.  Use the --tab option for this.

Output is unsorted, though all lines for one table should be output together.
For speed, all checksums are done in parallel (as much as possible) and may
complete out of the order in which they were started.  You might want to run
them through another script or command-line utility to make sure they are in the
order you want.  If you pipe the output through mysql-checksum-filter, you can
sort the output and/or avoid seeing output about tables that have no differences.

The columns in the output are as follows.  The database, table, and chunk come
first so you can sort by them easily (they are the "primary key").

=over

=item DATABASE

The database the table is in.

=item TABLE

The table name.

=item CHUNK

The chunk (see --chunksize).  Zero if you are not doing chunked checksums.

=item HOST

The server's hostname.

=item ENGINE

The table's storage engine.

=item COUNT

The table's row count, unless you specified to skip it.

=item CHECKSUM

The table's checksum, unless you specifed to skip it or the table has no rows.
some types of checksums will be 0 if there are no rows; others will print NULL.

=item TIME

The time the actual checksum and/or counting took.

=item WAIT

How long the checksum blocked before beginning.

=item STAT

The return value of MASTER_POS_WAIT().

=item LAG

How far the slave lags the master, as reported by SHOW SLAVE STATUS.

=back

=head1 QUERIES

If you are using innotop (see L<http://innotop.sourceforge.net/>),
mytop, or another tool to watch currently running MySQL queries, you may see
the checksum queries.  They look similar to this:

  REPLACE /*test.test_tbl:'2'/'5'*/ INTO test.checksum(db, ...

Since mysql-table-checksum's queries run for a long time and tend to be
textually very long, and thus won't fit on one screen of these monitoring
tools, I've been careful to place a comment at the beginning of the query so
you can see what it is and what it's doing.  The comment contains the name of
the table that's being checksummed, the chunk it is currently checksumming,
and how many chunks will be checksummed.  In the case above, it is
checksumming chunk 2 of 5 in table test.test_tbl.

=head1 BUGS

Please use the mailing lists, forums and other tools at
L<http://sourceforge.net/projects/mysqltoolkit> to discuss any bugs, feature
requests, etc.

=head1 SYSTEM REQUIREMENTS

You need Perl, DBI, DBD::mysql, and some core packages that ought to be
installed in any reasonably new version of Perl.

=head1 AUTHOR

Baron "Xaprb" Schwartz.

=head1 ACKNOWLEDGEMENTS

This is an incomplete list.  My apologies for omissions or misspellings.

Francois Saint-Jacques,
Giuseppe Maxia,
Heikki Tuuri,
James Briggs,
Martin Friebe,
Sergey Zhuravlev,

=head1 COPYRIGHT, LICENSE AND WARRANTY

This program is copyright (c) 2007 Baron Schwartz, baron at xaprb dot com.
Feedback and improvements are welcome.

THIS PROGRAM IS PROVIDED "AS IS" AND WITHOUT ANY EXPRESS OR IMPLIED
WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation, version 2; OR the Perl Artistic License.  On UNIX and similar
systems, you can issue `man perlgpl' or `man perlartistic' to read these
licenses.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA  02111-1307  USA.

=cut
