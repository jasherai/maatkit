#!/usr/bin/perl

# Advantage of bottom-up: parts can be parallelized
# TODO: put acknowledgements in the perdoc
# cite: Remote Comparison of Database Tables
# Allow iud param to only do inserts/updates/deletes
# Explain structure of tables, what __rem/__par mean etc
# top-down with where clauses allows mass insert/deletes much more efficiently.
# Look up the law of large numbers and justify why not to use SUM()
# Explain why @crc & $mask is the same as mod()
# Verify that the grouping isn't just the whole primary key
# Allow a threshold of expensiveness
# Allow soething other than REPLACE so not all columns get updated when the user
# isn't syncing all columns
# Allow to calculate, use, and delete summary tables separately
# Allow not to put indexes on summary tables in bottom-up
# TODO: another algorithm: binary search for where the corruption starts, say a
# chunk at a time of 10000 from start/end of table, then when a different chunk is
# found, binary search within that chunk to find the first row and report it.

# This program efficiently synchronizes data between two MySQL tables, which
# can be on different servers.
#
# This program is copyright (c) 2007 Baron Schwartz, baron at xaprb dot com.
# Feedback and improvements are welcome.
#
# THIS PROGRAM IS PROVIDED "AS IS" AND WITHOUT ANY EXPRESS OR IMPLIED
# WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
# MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE.
#
# This program is free software; you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, version 2; OR the Perl Artistic License.  On UNIX and similar
# systems, you can issue `man perlgpl' or `man perlartistic' to read these
# licenses.
#
# You should have received a copy of the GNU General Public License along with
# this program; if not, write to the Free Software Foundation, Inc., 59 Temple
# Place, Suite 330, Boston, MA  02111-1307  USA.

use strict;
use warnings FATAL => 'all';

use Data::Dumper;
use DBI;
use English qw(-no_match_vars);
use Getopt::Long;
use List::Util qw(sum max);
use POSIX qw(ceil);

our $VERSION = '@VERSION@';

$OUTPUT_AUTOFLUSH = 1;

my ( $sec, $min, $hour, $mday, $mon, $year, $wday, $yday, $isdst ) = localtime(time);

# ############################################################################
# Get configuration information.
# ############################################################################

# TODO change -e to --verbose
my %opt_spec = (
   h => { s => 'help|h',           d => 'Show this help message' },
   a => { s => 'algorithm|a=s',    d => 'Algorithm to use (topdown, bottomup)' },
   p => { s => 'print|p',          d => 'Print all sync queries to STDOUT' },
   b => { s => 'debug|b',          d => 'Print debugging output to STDOUT' },
   e => { s => 'explain|e=i',      d => 'Explain changes at levels 0..n in top-down algorithm' },
   x => { s => 'execute|x',        d => 'Execute queries required to sync' },
   s => { s => 'strategy|s=s',     d => 'Query strategy when syncing' },
   d => { s => 'drilldown|d=s',    d => 'Drilldown groupings for top-down algorithm' },
   r => { s => 'replicate|r',      d => 'Change on master. Implies --strategy=r'},
   f => { s => 'forupdate|f',      d => 'Use SELECT FOR UPDATE for checksums' },
   c => { s => 'columns|c=s',      d => 'Comma-separated column list' },
   B => { s => 'branchfactor|B=i', d => 'Branch factor for bottom-up algorithm' },
   P => { s => 'prefix|P=s',       d => 'Tablename prefix for bottom-up algorithm' },
   E => { s => 'engine|E=s',       d => 'Storage engine for bottom-up tables' },
   T => { s => 'temp|T=s',         d => 'Use temporary tables in bottom-up algorithm' },
   S => { s => 'size|S=i',         d => 'Table size in bottom-up algorithm' },
   C => { s => 'cleanup|C!',       d => 'Clean up scratch tables for bottom-up algorithm' },
);

my @opt_keys = qw( h a p b e x s d r f c B P E T S C );

# Generate a quasi-random string that's constant in a given day
# TODO: does this work on windows?
my $prefix = '__cmp' . crypt(sprintf('%d%02d%02d', $year + 1900, $mon, $mday), '00');
$prefix =~ s/\W+/_/g;

# This is the container for the command-line options' values to be stored in
# after processing.  Initial values are defaults.
my %opts = (
   h => 0,
   a => 'topdown',
   p => 0,
   b => 0,
   e => 0,
   x => 0,
   s => 's',
   d => '',
   r => 0,
   f => 0,
   c => '',
   B => 128,
   # Generate a quasi-random string that's constant in a given day
   P => $prefix,
   E => 'InnoDB',
   T => '',
   S => 0,
   C => undef,
);

# ############################################################################
# Get and process options
# ############################################################################

Getopt::Long::Configure('no_ignore_case', 'bundling');
GetOptions( map { $opt_spec{$_}->{s} => \$opts{$_} }  @opt_keys )
   or $opts{h} = 1;

$opts{h} = 1 if $opts{s} && $opts{s} !~ m/^(s|r)/;

# Make comma-separated lists into hashes.
if ( $opts{c} ) {
   $opts{c} = { map { $_ => 1 } split(/,\s*/, $opts{c}) };
}
$opts{T} = $opts{T} ? 'TEMPORARY' : '';
if ( !defined $opts{C} ) {
   $opts{C} = !$opts{T};
}
if ( $opts{r} ) {
   $opts{s} = 'r';
}

# ############################################################################
# Try to use the user's .my.cnf file.
# ############################################################################
my $dsn_defaults = {
   host => 'localhost',
   user => getlogin() || getpwuid($UID),
   port => 3306,
   key  => 'PRIMARY',
};
eval {
   my $homedir = $ENV{HOME} || $ENV{HOMEPATH} || $ENV{USERPROFILE} || '';
   my $filename = "$homedir/.my.cnf";
   if ( -f $filename ) {
      open my $conf_file, "<", "$homedir/.my.cnf" or die $OS_ERROR;
      while ( my $line = <$conf_file> ) {
         chomp $line;
         $line =~ s/(^\s*)|(\s*#.*$)//g;
         next unless $line;
         my ( $key, $val ) = split( /\s*=\s*/, $line );
         next unless defined $val;
         if ( $key eq 'host' )     { $dsn_defaults->{host} = $val; }
         if ( $key eq 'user' )     { $dsn_defaults->{user} = $val; }
         if ( $key =~ m/^pass/ )   { $dsn_defaults->{pass} = $val; }
         if ( $key eq 'database' ) { $dsn_defaults->{database} = $val; }
         if ( $key eq 'port' )     { $dsn_defaults->{port} = $val; }
      }
      close $conf_file;
   }
};

# ############################################################################
# Parse arguments saying which tables.  If the script doesn't have everything
# it needs, show help text.
# ############################################################################
my $source = parse_dsn(shift(@ARGV), {},      $dsn_defaults);
my $dest   = parse_dsn(shift(@ARGV), $source, $dsn_defaults);

if ( $opts{h} || !$dest ) {
   print "Usage: $PROGRAM_NAME [OPTION].. <source> <dest>\n\n  Options:\n\n";
   foreach my $key ( @opt_keys ) {
      my ( $long, $short ) = $opt_spec{$key}->{s} =~ m/^(\w+)(?:\|([^!+=]*))?/;
      $long  = "--$long" . ( $short ? ',' : '' );
      $short = $short ? " -$short" : '';
      printf("  %-13s %-4s %s\n", $long, $short, $opt_spec{$key}->{d});
   }
   print <<USAGE;

$PROGRAM_NAME finds and resolves data differences between two MySQL tables.
<source> and <dest> are data sources in the format
   user:pass\@host:port/database.table:key
Everything but the table name is optional, and defaults will be read from your
environment and your .my.cnf file if possible.  Values for <dest> default to the
values for <source>.

For more details, please read the documentation:

   perldoc $PROGRAM_NAME

USAGE
   exit(1);
}

# ############################################################################
# Lookup tables
# ############################################################################
my %code_for_algorithm = (
   topdown  => \&topdown,
   bottomup => \&bottomup,
);

# ############################################################################
# Do the work.
# ############################################################################
my $exit_status = 0;

foreach my $table ( $source, $dest ) {
   my $dbh = get_dbh($table);
   $table->{dbh} = $dbh;
   $table->{db_tbl} =
      join('.',
      map  {  $dbh->quote_identifier($_) }
      grep { $_ }
      ( $table->{database}, $table->{table} ));
   $table->{info} = get_tbl_struct($table);
   $table->{cols} = col_list(@{$table->{info}->{cols}});
}

if ( $code_for_algorithm{$opts{a}} ) {
   $code_for_algorithm{$opts{a}}->();
}
else {
   die "Sorry, algorithm '$opts{a}' unknown; try one of "
      . join('|', keys %code_for_algorithm);
}

exit $exit_status;

# ############################################################################
# Top-down algorithm
# ############################################################################

# TODO: for top-down, we should know approximately how many rows might be bad at any
# level in the recursion, and can give up unless the number is decreasing.
sub topdown {

   # Design a grouping strategy.
   my @groupings = map {
      { cols => [$_] }
   } $opts{d} =~ m/(\w+)/g;
   # TODO: check groupings are valid columns
   die "You must define drilldown groupings with --drilldown." unless @groupings;

   # Begin the recursion
   td_recurse(0, \@groupings, {});
}

# Figure out which groups are different between source and dest.
sub td_recurse {
   my ( $level, $groupings, $where ) = @_;

   my $grouping  = $groupings->[$level]->{cols};
   my $src_query = td_grouped_checksum_query($source, $grouping, $where);
   my $dst_query = td_grouped_checksum_query($dest,   $grouping, $where);
   my $src_cnt   = 0;
   my $dst_cnt   = 0;
   my %diffs;

   # Fetch from source:
   if ( $opts{b} ) {
      print '-- ', $src_query, "\n";
   }
   my $src_sth = $source->{dbh}->prepare($src_query);
   $src_sth->execute;
   while ( my $row = $src_sth->fetchrow_hashref ) {
      my $key = make_key($row, $grouping);
      $row->{_act_} = 'INSERT';
      $diffs{$key} = $row;
      $src_cnt++;
   }

   # Fetch from dest:
   if ( $opts{b} ) {
      print '-- ', $dst_query, "\n";
   }
   my $dst_sth = $dest->{dbh}->prepare($dst_query);
   $dst_sth->execute;
   while ( my $row = $dst_sth->fetchrow_hashref ) {
      my $key = make_key($row, $grouping);
      if ( $diffs{$key} ) {
         if ( $diffs{$key}->{crc} eq $row->{crc} ) {
            delete $diffs{$key};
         }
         else {
            $diffs{$key}->{_act_} = 'UPDATE';
         }
      }
      else {
         $row->{_act_} = 'DELETE';
         $diffs{$key} = $row;
      }
      $dst_cnt++;
   }

   if ( $opts{e} > $level ) {
      print join(' ', '-- LEVEL', $level + 1, $src_cnt, $dst_cnt,
         scalar(keys %diffs), make_where_clause($source->{dbh}, $where)), "\n";
   }

   if ( %diffs ) {
      foreach my $key ( sort keys %diffs ) {
         my $row = $diffs{$key};
         my %new_where = %$where;
         @new_where{@$grouping} = @{$row}{@$grouping};

         if ( $row->{_act_} eq 'DELETE' ) {
            # Deletes can be handled with a single query, pruning this whole
            # section of the recursion tree.
            td_handle_data_change('DELETE', $row, \%new_where, $row->{cnt});
         }
         elsif ( $level < $#{$groupings} ) {
            # There is more recursion to do.
            td_recurse($level + 1, $groupings, \%new_where);
         }
         else {
            # Non-recursed update/insert must be done a row at a time.
            td_bottom_out($level + 1, $row, \%new_where);
         }
      }
   }

}

# $row is not a row in the table -- it's a row from one of the grouped
# checksum queries.  But it is only one level removed from the individual rows
# in the table, hence the name bottom_out.
sub td_bottom_out {
   my ( $level, $row, $where ) = @_;

   my @key       = @{$source->{info}->{keys}->{$source->{key}}};
   my $src_query = td_ungrouped_checksum_query($source, \@key, $where);
   my $dst_query = td_ungrouped_checksum_query($dest,   \@key, $where);
   my $src_cnt   = 0;
   my $dst_cnt   = 0;
   my %diffs; # Each entry is a row in the table.

   # Fetch from source:
   my $src_sth = $source->{dbh}->prepare($src_query);
   $src_sth->execute;
   while ( my $row = $src_sth->fetchrow_hashref ) {
      my $key = make_key($row, \@key);
      $row->{_act_} = 'INSERT';
      $diffs{$key} = $row;
      $src_cnt++;
   }

   # Fetch from dest:
   my $dst_sth = $dest->{dbh}->prepare($dst_query);
   $dst_sth->execute;
   while ( my $row = $dst_sth->fetchrow_hashref ) {
      my $key = make_key($row, \@key);
      if ( $diffs{$key} ) {
         if ( $diffs{$key}->{crc} eq $row->{crc} ) {
            delete $diffs{$key};
         }
         else {
            $diffs{$key}->{_act_} = 'UPDATE';
         }
      }
      else {
         $row->{_act_} = 'DELETE';
         $diffs{$key} = $row;
      }
      $dst_cnt++;
   }

   if ( %diffs ) {

      if ( $opts{e} > $level ) {
         my %counts;
         map { $counts{$_->{_act_}}++ } values %diffs;
         foreach my $action ( keys %counts ) {
            print join(' ', '--', $action, scalar(keys %diffs),
            make_where_clause($source->{dbh}, $where)), "\n";
         }
      }

      foreach my $key ( sort keys %diffs ) {
         my $row = $diffs{$key};
         my %new_where = %$where;
         @new_where{@key} = @{$row}{@key};
         td_handle_data_change($row->{_act_}, $row, \%new_where);
      }
   }
}

sub td_handle_data_change {
   my ( $action, $row, $where ) = @_;

   my $which = $opts{r} ? $source : $dest;
   my $crit = make_where_clause($which->{dbh}, $where);

   if ( $action eq 'DELETE' ) {
      my $query = "DELETE FROM $which->{db_tbl} $crit";
      if ( $opts{p} ) {
         print STDOUT $query, ";\n";
      }
      if ( $opts{x} ) {
         $which->{dbh}->do($query);
      }
   }
   else {
      my $vals = $source->{dbh}->selectrow_hashref("SELECT $source->{cols} FROM $source->{db_tbl} $crit");
      my $query = "REPLACE INTO $which->{db_tbl}($which->{cols}) VALUES("
         . join(',', map { $which->{dbh}->quote($vals->{$_}) } @{$which->{info}->{cols}}) . ")";

      if ( $opts{p} ) {
         print STDOUT $query, ";\n";
      }
      if ( $opts{x} ) {
         $which->{dbh}->do($query);
         # TODO commit?
      }
   }
}

sub td_ungrouped_checksum_query {
   my ( $info, $key, $where ) = @_;
   my $dbh = $info->{dbh};
   my $tbl = $info->{info};

   # Columns that need to be in the checksum list.
   my @cols = grep { !exists($where->{$_}) } @{$tbl->{cols}};
   if ( $opts{c} ) {
      @cols = grep { exists($opts{c}->{$_}) } @cols;
   }
   my $cols = col_list(@cols);

   # To handle nulls, make a bitmap of nullable columns that are null.
   my @null = grep { $tbl->{null_hash}->{$_} } @cols;
   my $null = @null ? (", CONCAT(" . join(', ', map  { "ISNULL(`$_`)" } @null) . ")") : '';

   my $key_cols = col_list(@$key);
   my $crit = make_where_clause($dbh, $where);

   # Make the query.
   my $query = <<"   END";

      SELECT $key_cols, MD5(CONCAT_WS('#', $cols$null)) AS crc
      FROM $info->{db_tbl}
      $crit

   END
   return ( $query );
}

sub td_grouped_checksum_query {
   my ( $info, $groupby, $where ) = @_;
   my $dbh = $info->{dbh};
   my $tbl = $info->{info};

   # Columns that need to be in the checksum list.
   my @cols = grep { !exists($where->{$_}) } @{$tbl->{cols}};
   if ( $opts{c} ) {
      @cols = grep { exists($opts{c}->{$_}) } @cols;
   }
   my $cols = col_list(@cols);

   # To handle nulls, make a bitmap of nullable columns that are null.
   my @null = grep { $tbl->{null_hash}->{$_} } @cols;
   my $null = @null ? (", CONCAT(" . join(', ', map  { "ISNULL(`$_`)" } @null) . ")") : '';

   my $grp  = col_list(@$groupby);
   my $crit = make_where_clause($dbh, $where);
   my $lock = $opts{f} ? ' FOR UPDATE' : '';

   # Make the query.
   my $query = <<"   END";

      SELECT $grp, COUNT(*) AS cnt,
         CONCAT(
            LPAD(CONV(BIT_XOR(
               CAST(CONV(LEFT(\@CRC := MD5(CONCAT_WS('#', $cols$null)), 16), 16, 10) AS UNSIGNED)
               ), 10, 16), 16, '0'),
            LPAD(CONV(BIT_XOR(
               CAST(CONV(RIGHT(\@CRC, 16), 16, 10) AS UNSIGNED)
               ), 10, 16), 16, '0')
         ) AS crc
      FROM $info->{db_tbl}
      $crit
      GROUP BY $grp$lock

   END

   return ( $query );
}

# ############################################################################
# Bottom-up algorithm
# ############################################################################

sub bottomup {

   # Ensure branch factor is a power of two.
   $opts{B} = max(2, 2 ** round( log($opts{B}) / log(2) ));

   # Store table prefix in hashes
   $source->{prefix} = "$opts{P}_s_";
   $dest->{prefix}   = "$opts{P}_d_";

   # Begin with estimates of table size to allow calculating the checksum
   # remainder on the first level.
   my $est_size    = $opts{S} || max( estimate_size($source), estimate_size($dest) );
   my $level_est_1 = bu_num_levels($est_size);

   # Determine the data type needed for the remainder column.
   my $rem_col        = bu_size_to_type(( $opts{B} ** ($level_est_1 + 2)) - 1);
   $source->{rem_col} = $rem_col;
   $dest->{rem_col}   = $rem_col;

   # Build the initial checksum tables and calculate how many summary tables to build.  
   my $src_size    = bu_build_checksum( $source, $level_est_1 );
   my $level_est_2 = bu_num_levels( max( $est_size, $src_size ) );
   my $dst_size    = bu_build_checksum( $dest, $level_est_2 );
   my $true_size   = max( $src_size, $dst_size );
   my $levels      = bu_num_levels( $true_size );

   # Similar to the above, choose a type for the __cnt columns
   my $cnt_col        = bu_size_to_type($true_size);
   $source->{cnt_col} = $cnt_col;
   $dest->{cnt_col}   = $cnt_col;

   # Check and possibly rebuild remainders.
   if ( $levels > $level_est_1 + 2 ) {
      # The initial estimated number of levels caused the first-level tables to
      # have too-small data types, and I don't want to run ALTER TABLE; I'd
      # rather ask the user to re-run.
      die "Table size estimates ($est_size) were too small; specify --size $true_size";
   }
   if ( $level_est_1 != $levels ) {
      bu_rebuild_remainder($source, $levels);
   }
   if ( $level_est_2 != $levels ) {
      bu_rebuild_remainder($dest, $levels);
   }

   # Build the trees, merge them, and clean them up. TODO this part can be
   # parallelized with fork.
   bu_build_tree($source, $levels);
   bu_build_tree($dest,   $levels);
   bu_merge_tree($dest, $source, $levels);
   bu_cleanup_tree($dest, $source) if $opts{C};
}

# Builds the first-level checksum table and returns the number of rows in it.
sub bu_build_checksum {
   my ($info, $levels) = @_;
   my $dbh    = $info->{dbh};
   my $tbl    = $info->{info};
   my $pk     = col_list( @{ $tbl->{keys}->{$info->{key}} } );
   my @cols   = @{ $tbl->{cols} };
   my $cols   = col_list(@cols);
   my $pks    = join( ',', @{ $tbl->{defs} }{ @{ $tbl->{keys}->{$info->{key}} } } );
   my @null   = grep { $tbl->{null_hash}->{$_} } @cols;
   my $null = @null
            ? ( ", CONCAT(" . join( ', ', map {"ISNULL(`$_`)"} @null ) . ")" ) : '';
   my $name = "$info->{prefix}_0";
   my $mask = ($opts{B} ** ($levels - 1)) - 1;

   # Create the table
   $dbh->do("DROP TABLE IF EXISTS $name");
   my $table_query = <<"   END";
      CREATE $opts{T} TABLE `$info->{database}`.`$name` (
         $pks,
         __crc char(32) not null,
         __rem $info->{rem_col} UNSIGNED not null,
         KEY(__rem),
         PRIMARY KEY($pk)
      ) ENGINE=$opts{E}
   END
   $dbh->do($table_query);

   # Populate it
   my $sum_query = <<"   END";
      INSERT INTO `$info->{database}`.`$name`($pk, __crc, __rem)
      SELECT $pk,
         MD5(CONCAT_WS('#', $cols$null)) AS __crc,
         CAST(CONV(RIGHT(MD5(CONCAT_WS('#', $pk)), 16), 16, 10) AS UNSIGNED) & $mask AS __rem
      FROM $info->{db_tbl}
   END
   my $sth = $dbh->prepare($sum_query);
   $sth->execute();
   return $sth->rows;
}

sub bu_rebuild_remainder {
   my ( $info, $levels ) = @_;
   my $pk   = col_list( @{ $info->{info}->{keys}->{$info->{key}} } );
   my $mask = ($opts{B} ** ($levels - 1)) - 1;
   my $name = "$info->{prefix}_0";
   my $query = <<"   END";
      UPDATE `$info->{database}`.`$name` SET __rem =
         CAST(CONV(RIGHT(MD5(CONCAT_WS('#', $pk)), 8), 16, 10) AS UNSIGNED) & $mask
   END
   $info->{dbh}->do($query);
}

# Builds the nth-level summary tables.
# TODO: allow to use other hash functions like SHA1, and genericize the substringing code
# and the required size of the columns.
sub bu_build_tree {
   my ($info, $levels) = @_;
   my $dbh = $info->{dbh};
   my $tbl = $info->{info};

   # Do from 1 because level 0 has already been built.
   foreach my $i ( 1 .. $levels ) {
      my $modulo   = int($opts{B} ** ( $levels - $i - 1 ));
      my $last_mod = $modulo * $opts{B};
      my $this_tbl = "$info->{prefix}_" . $i;
      my $last_tbl = "$info->{prefix}_" . ( $i - 1 );
      my $mask     = max(0, $modulo - 1);
      my $cnt_sum  = $i > 1 ? 'SUM(__cnt)' : 'COUNT(*)';

      # Create the table
      $dbh->do("DROP TABLE IF EXISTS $this_tbl");
      my $table_query = <<"      END";
         CREATE $opts{T} TABLE `$info->{database}`.`$this_tbl` (
            __par int not null,
            __crc char(32) not null,
            __rem $info->{rem_col} UNSIGNED not null,
            __cnt $info->{cnt_col} unsigned not null,
            KEY(__rem),
            PRIMARY KEY(__par)
         ) ENGINE=$opts{E}
      END
      $dbh->do($table_query);

      # Populate it
      my $sum_query = <<"      END";
         INSERT INTO `$info->{database}`.`$this_tbl`
            (__par, __crc, __rem, __cnt)
         SELECT __rem,
            CONCAT(
               LPAD(CONV(BIT_XOR(CAST(CONV(SUBSTRING(__crc, 1,  16), 16, 10) as unsigned)), 10, 16), 16, '0'),
               LPAD(CONV(BIT_XOR(CAST(CONV(SUBSTRING(__crc, 17, 16), 16, 10) as unsigned)), 10, 16), 16, '0')
            ) AS this_crc,
            __rem & $mask AS this_remainder,
            $cnt_sum AS total_rows
         FROM `$info->{database}`.`$last_tbl`
         GROUP BY __rem
         ORDER BY NULL
      END
      $dbh->do($sum_query);
   }
}

# There are actually 1 more than $levels summary tables; there are tables 0 ..
# $levels (see bu_build_tree).  Level 0 has a different structure.  It has
# primary keys instead of a __par pointer.
sub bu_merge_tree {
   my ($dest, $source, $levels) = @_;

   my $level = $levels;
   my @bad_parents; # List of parents that must differ at current level
   my ( $rows_in_src, $rows_in_dst ) = (0,0);

   # Lists of rows that differ in the target tables.
   my (@to_update, @to_delete, @to_insert);
   my (@bulk_insert, @bulk_delete);
   
   do {
      my $src_sth = bu_fetch_level($source, $level, @bad_parents);
      my $dst_sth = bu_fetch_level($dest,   $level, @bad_parents);

      # Reset for next loop, once used to fetch this loop
      @bad_parents = ();
      $rows_in_src = $rows_in_dst = 0;

      my @src_key = $level ? '__par' : @{$source->{info}->{keys}->{$source->{key}}};
      my @dst_key = $level ? '__par' : @{$dest->{info}->{keys}->{$dest->{key}}};
      my ($sr, $dr); # Source row, dest row

      # The statements fetch in order, so use a 'merge' algorithm of shifting
      # forward after they match.  This is essentially a FULL OUTER JOIN.
      MERGE:
      while ( 1 ) { # Exit this loop via 'last'

         if ( !$sr ) {
            $sr = $src_sth->fetchrow_hashref;
            if ( $sr ) {
               $rows_in_src += $sr->{__cnt} || 1;
            }
         }
         if ( !$dr ) {
            $dr = $dst_sth->fetchrow_hashref;
            if ( $dr ) {
               $rows_in_dst += $dr->{__cnt} || 1;
            }
         }

         last MERGE unless $sr || $dr;

         # If the current row is the "same row" on both sides...
         if ( $sr && $dr && bu_key_eq($sr, $dr, \@src_key, \@dst_key) ) {

            # The "same" row descends from parents that differ.
            if ( $sr->{__crc} ne $dr->{__crc} ) {
               if ( $level ) {
                  push @bad_parents, $sr->{__par};
               }
               else {
                  push @to_update, $sr;
               }
            }
            $sr = $dr = undef;
         }

         # The row in the source doesn't exist at the destination
         elsif ( !$dr || ( $sr && bu_key_le($sr, $dr, \@src_key, \@dst_key) ) ) {
            if ( $level ) {
               push @bulk_insert, $sr;
            }
            else {
               push @to_insert, $sr;
            }
            $sr = undef;
         }

         # Symmetric to the above
         elsif ( !$sr || ( $dr && bu_key_le($dr, $sr, \@dst_key, \@src_key) ) ) {
            if ( $level ) {
               push @bulk_delete, $dr;
            }
            else {
               push @to_delete, $dr;
            }
            $dr = undef;
         }

         else {
            die "This code should never have run.  This is a bug.";
         }
      }

      my $sum_bulk_ins = sum(map { $_->{__cnt} } @bulk_insert) || 0;
      my $sum_bulk_del = sum(map { $_->{__cnt} } @bulk_delete) || 0;

      if ( $opts{e} ) {
         printf("-- Level %1d summary: %4d parents %4d src rows %4d dst rows\n",
            $level, scalar(@bad_parents), $rows_in_src, $rows_in_dst);
         printf("-- Level %1d changes: %4d updates %4d inserts  %4d deletes %4d total\n",
            $level, scalar(@to_update), scalar(@to_insert) + $sum_bulk_ins,
            scalar(@to_delete) + $sum_bulk_del,
            scalar(@to_update) + scalar(@to_insert) + $sum_bulk_ins
               + scalar(@to_delete) + $sum_bulk_del
         );
         printf("-- Level %1d bulk-op: %4d inserts %4d ins-rows %4d deletes %4d del-rows\n",
            $level, scalar(@bulk_insert), $sum_bulk_ins,
            scalar(@bulk_delete), $sum_bulk_del);
      }

      # TODO if ( $opts{m} < @bad_parents
      # TODO: we can already look at $sr->{__cnt} - $dr->{__cnt}
      # and abort if rowcount too high

      $level--;
   } while ( $level >= 0 && @bad_parents );

   # TODO: estimate # rows needing change before going further
   bu_handle_data_change('UPDATE', @to_update);
   bu_handle_data_change('INSERT', @to_insert);
   bu_handle_data_change('DELETE', @to_delete);
   bu_handle_bulk_change('INSERT', $levels, $source, @bulk_insert);
   bu_handle_bulk_change('DELETE', $levels, $dest,   @bulk_delete);
}

sub bu_cleanup_tree {
   my @servers = @_;
   foreach my $info ( @servers ) {
      my @tables = @{$info->{dbh}->selectcol_arrayref("SHOW TABLES FROM `$info->{database}`")};
      foreach my $table ( grep { m/^$info->{prefix}_\d+$/ } @tables ) {
         my $query = "DROP TABLE `$info->{database}`.`$table`";
         if ( $opts{b} ) {
            print '-- ', $query, "\n";
         }
         $info->{dbh}->do($query);
      }
   }
}

# Finds atomic rows that got folded into an entirely insertable or deleteable
# part of the tree.
sub bu_handle_bulk_change {
   my ( $action, $levels, $info, @rows ) = @_;
   my $pk = col_list( @{ $info->{info}->{keys}->{$info->{key}} } );
   my @rows_to_do;

   foreach my $row ( @rows ) {

      # TODO: optimization.
      # This is logically correct, but MySQL won't use indexes:
      # "SELECT $pk FROM $info->{prefix}_0 WHERE __rem & $row->{__par} = $row->{__par}"
      # This ends up looking like __rem & 3 = 3.  This will match any of the
      # following (partial list):
      # +-------+--------+
      # | __rem | binary |
      # +-------+--------+
      # |     3 |     11 |
      # |    11 |   1011 |
      # |    15 |   1111 |
      # |    19 |  10011 |
      # |    31 |  11111 |
      # |    51 | 110011 |
      # |    59 | 111011 |
      # +-------+--------+
      # Notice the rightmost two bits are the same in each number.  All these
      # combinations can be generated by adding 3 and every number from 4 to the
      # maximum possible __rem value.  This is easiest to do by mentally
      # left-shifting by the appropriate number of digits and adding.  Suppose
      # $levels is such that the maximum __rem is 63; something like
      # $i = 1; while ( $i * 4 < 63 ) { print 3 + $i * 4; $i++; }
      # If the list is really long, it'll be less efficient for MySQL, so I'd
      # say only do this if the list is less than 20% of the number of __rem
      # values.

      my $parent   = $row->{__par};
      my $query = "SELECT $pk FROM $info->{prefix}_0 WHERE __rem & $parent = $parent";

      if ( $opts{b} ) {
         print '-- ', $query, "\n";
      }
      my $vals = $info->{dbh}->selectall_arrayref($query, { Slice => {} });
      push @rows_to_do, @$vals;
   }

   bu_handle_data_change($action, @rows_to_do);
}

sub bu_handle_data_change {
   my ( $action, @rows ) = @_;

   my $which = $opts{r} ? $source : $dest;
   my $dbh   = $which->{dbh};

   foreach my $row ( @rows ) {
      delete $row->{__crc}; # Now the row can be used as a WHERE clause
      my $crit = make_where_clause($dbh, $row);

      if ( $action eq 'DELETE' ) {
         my $query = "DELETE FROM $which->{db_tbl} $crit";
         if ( $opts{p} ) {
            print STDOUT $query, ";\n";
         }
         if ( $opts{x} ) {
            $dbh->do($query);
         }
      }
      else {
         my $vals = $source->{dbh}->selectrow_hashref(
            "SELECT $source->{cols} FROM $source->{db_tbl} $crit");

         my $query;
         if ( $opts{s} eq 'r' || $action eq 'INSERT' ) {
            my $verb = $opts{s} eq 'r' ? 'REPLACE' : 'INSERT';
            $query = "$verb INTO $which->{db_tbl}($which->{cols}) VALUES("
               . join(',', map { $dbh->quote($vals->{$_}) }
                  @{$which->{info}->{cols}}) . ")";
         }
         else {
            $query = "UPDATE $which->{db_tbl} SET "
               . join(',',
                  map { $dbh->quote_identifier($_) . '=' .  $dbh->quote($vals->{$_}) }
                  @{$which->{info}->{cols}});
         }

         if ( $opts{p} ) {
            print STDOUT $query, ";\n";
         }
         if ( $opts{x} ) {
            $dbh->do($query);
            # TODO commit?
         }
      }
   }
}

# I named this 'le' for clarity about what it does, even though the way it's
# used is in a strict 'lt' sense because 'bu_key_eq' would prevent the code from
# reaching this function.  NULL sorts before defined values in MySQL, so I
# consider undef "less than."
sub bu_key_le {
   my ( $r1, $r2, $key_1, $key_2 ) = @_;
   foreach my $i ( 0 .. @$key_1 - 1 ) {
      my $l = $r1->{$key_1->[$i]};
      my $r = $r2->{$key_2->[$i]};
      if ( (defined $l && !defined $r)
         || ( defined $l && defined $r && $l gt $r )
      ) {
         return 0;
      }
      elsif ( (!defined $l && defined $r)
         || ( defined $l && defined $r && $l lt $r )
      ) {
         return 1;
      }
   }
   return 1;
}

sub bu_key_eq {
   my ( $r1, $r2, $key_1, $key_2 ) = @_;
   foreach my $i ( 0 .. @$key_1 - 1 ) {
      my $l = $r1->{$key_1->[$i]};
      my $r = $r2->{$key_2->[$i]};
      my $parity = defined($l) + defined($r);
      if ( $parity == 1 || ( $parity == 2 && $l ne $r )) {
         return 0;
      }
   }
   return 1;
}

sub bu_fetch_level {
   my ( $info, $level, @bad_remainders ) = @_;
   my $dbh = $info->{dbh};
   my $tbl = "$info->{prefix}_" . $level;

   my $cols  = $level
             ? '__par, __cnt'
             : col_list( @{ $info->{info}->{keys}->{$info->{key}} } );
   my $where = @bad_remainders
             ? "WHERE __rem in(" . join(',', @bad_remainders) . ")"
             : '';
   my $order = $level
             ? '__par'
             : col_list( @{ $info->{info}->{keys}->{$info->{key}} } );

   my $query = "SELECT $cols, __crc FROM $tbl $where ORDER BY $order";
   if ( $opts{b} ) {
      print '-- ', $query, "\n";
   }
   my $sth = $dbh->prepare($query);
   $sth->execute();
   return $sth;
}

# Returns how many levels of tables you need to build for a table of a given
# size.  If your B factor is 4 and you pass in 100, you need the summaries
# to be grouping mod 64, 16, 4, 1 so you need 4 levels (5 total including 0,
# which is row-for-row with the real table).
sub bu_num_levels {
   my ( $size ) = @_;
   return int( log( $size / $opts{B} ) / log(2) );
}

# Returns the maximum modulus that the tables will need.
sub bu_size_to_type {
   my ( $size ) = @_;
   return $size < 256        ? 'TINYINT'
        : $size < 65536      ? 'SMALLINT'
        : $size < 16777216   ? 'MEDIUMINT'
        : $size < 4294967296 ? 'INT'
        :                      'BIGINT';
}

# ############################################################################
# Subroutines
# ############################################################################

# Parses a DSN in login:pass@host:port/database.table:key format
sub parse_dsn {
   my ($dsn, $prev, $defs) = @_;
   return unless $dsn;
   $prev ||= {};
   $defs ||= {};

   my ( $user, $pass, $host, $port, $database, $table, $key) = $dsn =~ m{
      (?:
         (.+?)       # Username
         (?::(.+))?  # Optional password
      @)?            # User-pass is optional
      (?:
         (.+?)       # Hostname
         (?::(.+))?  # Optional port
      /)?            # Host-port is optional
      (?:
         (.+?)       # Database
      \.)?           # Database is optional
      ([^:]+)        # Table is required
      (?::
         (.+)        # Key/index
      )?             # Index is optional
      }xsm or return undef;

   return {
      user     => coalesce( $user,     $prev->{user},     $defs->{user} ),
      pass     => coalesce( $pass,     $prev->{pass},     $defs->{pass} ),
      host     => coalesce( $host,     $prev->{host},     $defs->{host} ),
      port     => coalesce( $port,     $prev->{port},     $defs->{port} ),
      database => coalesce( $database, $prev->{database}, $defs->{database} ),
      table    => coalesce( $table,    $prev->{table} ),
      key      => coalesce( $key,      $prev->{key},      $defs->{key} ),
   };
}

sub get_tbl_struct {
   my ( $info ) = @_;
   my $ddl = ($info->{dbh}->selectrow_array("SHOW CREATE TABLE $info->{db_tbl}"))[1];
   my @defs = $ddl =~ m/^(\s+`.*?),?$/gm;
   my @cols = map { $_ =~ m/`([^`]+)`/g } @defs;
   my @null = map { $_ =~ m/`([^`]+)`/g } grep { $_ !~ m/NOT NULL/ } @defs;
   my %keys =
      map {
         my ($name) = $_ =~ m/(PRIMARY|`[^`]*`)/;
         my ($cols) = $_ =~ m/\((.+)\),?$/;
         $name =~ s/`//g;
         ($name, [ grep { m/[^,]/ } split('`', $cols) ])
      }
      $ddl =~ m/^  ((?:[A-Z]+ )?KEY .*)$/gm;
   my %alldefs;
   @alldefs{@cols} = @defs;

   if ( !exists $keys{$info->{key}} ) {
      die "No such key $info->{key} in table $info->{host}/$info->{db_tbl}";
   }

   return {
      cols      => \@cols,
      col_hash  => { map { $_ => 1 } @cols },
      null      => \@null,
      null_hash => { map { $_ => 1 } @null },
      keys      => \%keys,
      defs      => \%alldefs,
   };
}

# Get a size estimate (not a precise count because that may be very slow).
# Can't use COUNT(*) because it might be optimized away and so 'rows' could be
# null.  And in tables where there is no NULL column, again it could be
# optimized away, so I must generate a WHERE clause that will defeat this.
sub estimate_size {
   my ($info) = @_;
   my ( $pkcol ) = @{$info->{info}->{keys}->{$info->{key}}};
   my $query = "EXPLAIN SELECT COUNT("
      . join("), COUNT(", split(',', col_list(@{$info->{info}->{cols}})))
      . ") FROM $info->{db_tbl} "
      . "WHERE COALESCE(`$pkcol`, `$pkcol`) = `$pkcol`";
   if ( $opts{b} ) {
      print '-- ', $query, "\n";
   }
   return $info->{dbh}->selectrow_hashref($query)->{rows};
}

sub round {
   my ($number) = @_;
   return int( $number + .5 );
}

sub make_where_clause {
   my ( $dbh, $where ) = @_;
   my @clauses = map {
      my $val = $where->{$_};
      my $sep = defined $val ? ' = ' : ' IS ';
      $dbh->quote_identifier($_) . $sep . $dbh->quote($val);
   } keys %$where;
   my $clause = @clauses ? 'WHERE ' . join(' AND ', @clauses) : '';
   return $clause;
}

sub make_key {
   my ( $row, $cols ) = @_;
   return join('#', map { defined $row->{$_} ? $row->{$_} : 'NULL' } @$cols);
}

sub get_dbh {
   my ( $conn ) = @_;
   return DBI->connect(
      "DBI:mysql:$conn->{database};host=$conn->{host};port=$conn->{port}",
      $conn->{user}, $conn->{pass},
      { RaiseError => 1, PrintError => 1, AutoCommit => $opts{k} ? 0 : 1 } )
      or die("Can't connect to DB: $OS_ERROR");
}

sub col_list {
   return '`' . join('`,`', @_) . '`';
}

sub coalesce {
   my $i = 0;
   while ( $i < @_ && !defined $_[$i] ) {
      $i++;
   }
   return $_[$i];
}

# ############################################################################
# Documentation
# ############################################################################
=pod

=head1 NAME

mysql-table-sync - Efficiently synchronize data between two MySQL tables.

=head1 DESCRIPTION

Given two MySQL tables already known to be different, and assuming the
differences are moderately small, find and resolve the differences between the
tables.

The DBA must choose the algorithm and parameters to use when reconciling
differences between the tables.  See below for help making this decision.
Different algorithms have more or less network traffic, impact on the servers,
or work better in certain circumstances.  The tool supports a variety of
algorithms so you can resolve the differences as efficiently as possible within
whatever parameters matter to you.

=head1 SYSTEM REQUIREMENTS

You need Perl, DBI, DBD::mysql, and some core packages that ought to be
installed in any reasonably new version of Perl.

=head1 OVERVIEW

=head1 OUTPUT

=head1 COPYRIGHT, LICENSE AND WARRANTY

This program is copyright (c) 2007 Baron Schwartz, baron at xaprb dot com.
Feedback and improvements are welcome.

THIS PROGRAM IS PROVIDED "AS IS" AND WITHOUT ANY EXPRESS OR IMPLIED
WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation, version 2; OR the Perl Artistic License.  On UNIX and similar
systems, you can issue `man perlgpl' or `man perlartistic' to read these
licenses.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc., 59 Temple
Place, Suite 330, Boston, MA  02111-1307  USA.

=head1 AUTHOR

Baron Schwartz, baron at xaprb dot com.

=cut
