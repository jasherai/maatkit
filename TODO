A tool (or a feature on mk-slave-prefetch or mk-heartbeat) to watch how fast a
slave is replicating, in bytes/sec.

Debugging output when daemonizing, like mk-slave-restart has.

Add timezone to DSN syntax

Integrate mk-slave-delay with mk-heartbeat.

Make mk-slave-delay implement a different definition of 'delay' as per Defition
2 in bug report #1959496.

a tool to load tables/indexes into cache by the techniques Peter mentioned:
http://www.mysqlperformanceblog.com/2008/05/01/quickly-preloading-innodb-tables-in-the-buffer-pool/

Make mk-table-checksum checksum only newly inserted rows (as defined by the
checksum table).  Make it able to read from a table that defines tables to
checksum and the desired strategies.

Add a --charset option to all tools, like mk-table-sync has.

Add a --setvars option to all tools, so one can set wait_timeout etc.
Make it set the wait_timeout by default.

mk-log-server: start a server that can serve the given log files.

mysqldiff: http://www.adamspiers.org/computing/mysqldiff/
http://www.mysqldiff.org/
(mk-schema-sync or similar tool should be in SVN history)

query sniper:
   * http://www.stillhq.com/mysql/000008.html
   * Allow up to max_connections-X connections
   * Specify users/hosts NOT to kill (by default root/localhost)
   * http://google-mysql-tools.googlecode.com/svn/trunk/mypgrep.py

Log parsing and coloring:

   Swallow a log file and output only the selected fields.  This could be
   piped to a colorizer or pushed into mk-query-profiler.

   We need to update our slow-log tool to tell us the most recent time a query
   was executed

   Query rewriter: collapse INSERT ... VALUES (), (), (), ()..... to reduce the
   number of VALUES lists to just one, with a (VALUES_LIST_REPEATED) token after
   that.

A script to copy files in parallel with netcat.

#!/bin/bash

set -e
set -u

# #######################################################################
# Arguments
# #######################################################################
SRC=$1
DST=$2
SDIR=$3
DDIR=$4
EXCL=$5

running=0
port=12345

function copyfile () {
   file=$1;
   port=$2;
   echo "$file, $port";
   #(sleep 10; touch forked)&
   #while [ ! -e forked ]; do
      #echo "sleeping";
      #sleep 1;
   #done
   #rm forked
}

for file in `ssh $SRC "du $SDIR/*" | grep -v "'$EXCL'" | sort -nr | awk '{print $2}'`; do
   let port=port+1;
   copyfile $file $port;
done

Progress calculations:
   *  Look at PROCESSLIST, grab the query, EXPLAIN it, watch handlers, do the
   * the problem is really it only works for some query types 
   * If second query would be Ref for example you would not find it
   because you can't see first table Ref from second table Ref
   * But in particular case of FT Scan + bunch of refs it is very helpful
   * Yes, true: but, you could calculate from the rows and access types
   how many of each type of Handler operation you expect to see for the whole
   query, right?
   * It would be very hard to do for subqueries, though :)
   * what about progress for mysqldump ?
   * and reverse - mysql < from_dump.sql

Make visual-explain tell which columns are used in the index.
